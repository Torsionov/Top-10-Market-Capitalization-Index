{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import urllib.request, requests, json, re, time, os, difflib, itertools\n",
    "import pandas as pd\n",
    "from multiprocessing.dummy import Pool\n",
    "from datetime import datetime\n",
    "try:\n",
    "    import httplib\n",
    "except:\n",
    "    import http.client as httplib\n",
    "    \n",
    "login = 'YOUR LOGIN'\n",
    "password = 'YOUR PASSWORD'\n",
    "\n",
    "url = 'https://ycharts.com/login?next=/companies/AAPL/market_cap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"market_capitalization_data\"+os.sep+\"csv\"+os.sep\n",
    "if not os.path.isdir(csv_path):\n",
    "    os.makedirs(csv_path)\n",
    "\n",
    "def check_internet():\n",
    "    conn = httplib.HTTPConnection(\"www.google.com\", timeout=5)\n",
    "    try:\n",
    "        conn.request(\"HEAD\", \"/\")\n",
    "        conn.close()\n",
    "        return True\n",
    "    except:\n",
    "        conn.close()\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stocks: 106328\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>2</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Name</th>\n",
       "      <th>Exchange</th>\n",
       "      <th>Category Name</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OEDV</td>\n",
       "      <td>Osage Exploration and Development, Inc.</td>\n",
       "      <td>PNK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>NMS</td>\n",
       "      <td>Electronic Equipment</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAC</td>\n",
       "      <td>Bank of America Corporation</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>Money Center Banks</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "2 Ticker                                     Name Exchange  \\\n",
       "0   OEDV  Osage Exploration and Development, Inc.      PNK   \n",
       "1   AAPL                               Apple Inc.      NMS   \n",
       "2    BAC              Bank of America Corporation      NYQ   \n",
       "\n",
       "2         Category Name Country  \n",
       "0                   NaN     USA  \n",
       "1  Electronic Equipment     USA  \n",
       "2    Money Center Banks     USA  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_file_path = \"Yahoo Ticker Symbols - September 2017.xlsx\"\n",
    "temp_df = pd.read_excel(ticker_file_path)\n",
    "temp_df = temp_df.drop(temp_df.columns[[5, 6, 7]], axis=1)\n",
    "headers = temp_df.iloc[2]\n",
    "df  = pd.DataFrame(temp_df.values[3:], columns=headers)\n",
    "print(\"Total stocks:\",len(df))\n",
    "\n",
    "query_urls=[]\n",
    "for ticker in df['Ticker']:\n",
    "    query_urls.append(\"https://ycharts.com/login?next=/companies/\"+ticker+\"/market_cap\")\n",
    "    \n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connection(url):\n",
    "    driver = webdriver.Firefox(executable_path=r'C:\\dr\\geckodriver.exe')\n",
    "    driver.get(url)\n",
    "\n",
    "    for i in driver.get_cookies():\n",
    "        if i['name'] == 'csrftoken':\n",
    "            csrftoken = i['value']\n",
    "        elif i['name'] == 'csrf':\n",
    "            csrftoken = i['value']\n",
    "    driver.get(url)\n",
    "\n",
    "    s_username = driver.find_element_by_name('username')\n",
    "    s_password = driver.find_element_by_name('password')\n",
    "    s_continue = driver.find_element_by_css_selector('.btn-block')\n",
    "\n",
    "    s_username.send_keys(login)\n",
    "    s_password.send_keys(password)\n",
    "    s_continue.click()\n",
    "    time.sleep(2)\n",
    "    driver.find_element_by_link_text('Quickflows').click()\n",
    "    return driver\n",
    "\n",
    "def fill_data(soup, data):\n",
    "    div_r = soup.find('div',  attrs={\"class\" : \"dataColRt\"})\n",
    "    div_l = soup.find('div',  attrs={\"class\" : \"dataColLeft\"})\n",
    "    r_rows = div_r.find_all('tr')\n",
    "    l_rows = div_l.find_all('tr')\n",
    "    for rows_set in (l_rows, r_rows):\n",
    "        for row in rows_set:\n",
    "            row_data = []\n",
    "            if row.find_all('td'):\n",
    "                for cell in row.find_all('td'):\n",
    "                    val = cell.get_text().strip()\n",
    "                    row_data.append(val)\n",
    "                data.append(row_data)\n",
    "def data_scraping(url):\n",
    "    data = []\n",
    "    driver = connection(url)\n",
    "    soup = BeautifulSoup(driver.page_source,\"lxml\")\n",
    "    fill_data(soup, data) #first page\n",
    "    \n",
    "    while True: #others page\n",
    "        try:\n",
    "            driver.find_element_by_link_text('Next').click()\n",
    "            time.sleep(0.1)\n",
    "            soup = BeautifulSoup(driver.page_source,\"lxml\")\n",
    "            for div in soup.find_all(\"div\", {'class':'ng-hide'}): \n",
    "                div.decompose()\n",
    "            fill_data(soup, data)\n",
    "        except: break\n",
    "    driver.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market_cap_data(query_url,json_path,csv_path):\n",
    "    \n",
    "    stock_id=query_url.split('/market_cap')[0].split(\"companies/\")[1]\n",
    "\n",
    "    if os.path.exists(csv_path+stock_id+'.csv') and os.stat(csv_path+stock_id+'.csv').st_size != 0:\n",
    "        print(\"<<<  Market capialization data of \"+stock_id+\" already exists\")\n",
    "        return\n",
    "    \n",
    "    while not check_internet():\n",
    "        print(\"Could not connect, trying again in 5 seconds...\")\n",
    "        time.sleep(5)\n",
    "\n",
    "    try:\n",
    "        html = requests.get(\"https://ycharts.com/companies/\"+stock_id+\"/market_cap\")\n",
    "        if html.status_code == 200:\n",
    "            data = data_scraping(query_url)\n",
    "\n",
    "    except:\n",
    "        print(\"|||  Market capialization data of \"+stock_id+\" doesn't exist\")\n",
    "        return\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            for i, row in enumerate(data):\n",
    "           #     data[i][0] = datetime.strptime(row[0], \"%B %d, %Y\")\n",
    "                if row[1][-1] == \"T\":\n",
    "                    data[i][1] =  int(float(row[1][:-1]) * 1000000000000)\n",
    "                elif row[1][-1] == 'B':\n",
    "                    data[i][1] =  int(float(row[1][:-1]) * 1000000000)\n",
    "                elif row[1][-1] == 'M':\n",
    "                    data[i][1] =  int(float(row[1][:-1]) * 1000000)\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "            df = pd.DataFrame(data={\"Date\": pd.Series((v[0] for v in data)), \"Market_cap\": pd.Series((v[1] for v in data))})\n",
    "\n",
    "            if os.path.exists(csv_path+stock_id+'.csv'):\n",
    "                os.remove(csv_path+stock_id+'.csv')\n",
    "            df.to_csv(csv_path+stock_id+'.csv', sep=',', index=None)\n",
    "            \n",
    "            print(\">>>  Market capialization data of \"+stock_id+\" saved\")\n",
    "            \n",
    "        except:\n",
    "            print(\">>>  Market capialization data of \"+stock_id+\" could not be saved\")\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>  Market capialization data of OEDV could not be saved\n",
      "<<<  Market capialization data of AAPL already exists\n",
      "<<<  Market capialization data of BAC already exists\n",
      "<<<  Market capialization data of AMZN already exists\n",
      ">>>  Market capialization data of JUP.L could not be saved>>>  Market capialization data of ORRP could not be saved\n",
      "\n",
      "<<<  Market capialization data of T already exists\n",
      "<<<  Market capialization data of GOOG already exists\n",
      "<<<  Market capialization data of ORRAF already exists\n",
      "<<<  Market capialization data of MO already exists\n",
      "<<<  Market capialization data of DAL already exists\n",
      "<<<  Market capialization data of AA already exists\n",
      "<<<  Market capialization data of AXP already exists\n",
      "<<<  Market capialization data of DD already exists\n",
      "<<<  Market capialization data of BABA already exists\n",
      "<<<  Market capialization data of ABT already exists\n",
      "<<<  Market capialization data of UA already exists\n",
      "<<<  Market capialization data of AMAT already exists\n",
      "<<<  Market capialization data of AMGN already exists\n",
      "<<<  Market capialization data of AAL already exists\n",
      "<<<  Market capialization data of AIG already exists\n",
      "<<<  Market capialization data of ALL already exists\n",
      "<<<  Market capialization data of ADBE already exists\n",
      "<<<  Market capialization data of GOOGL already exists\n",
      "<<<  Market capialization data of ACN already exists\n",
      "<<<  Market capialization data of ABBV already exists\n",
      "<<<  Market capialization data of MT already exists\n",
      "<<<  Market capialization data of LLY already exists\n",
      ">>>  Market capialization data of AGN could not be saved\n",
      "<<<  Market capialization data of APA already exists\n",
      "<<<  Market capialization data of ADP already exists\n",
      ">>>  Market capialization data of ORP.PA could not be saved\n",
      "<<<  Market capialization data of OROVY already exists\n",
      ">>>  Market capialization data of J69U.SI could not be saved\n",
      ">>>  Market capialization data of ORL.TA could not be saved\n",
      ">>>  Market capialization data of APC could not be saved\n",
      "<<<  Market capialization data of AKAM already exists\n",
      "<<<  Market capialization data of NLY already exists\n",
      ">>>  Market capialization data of ITXT.PA could not be saved\n",
      "<<<  Market capialization data of IGM.TO already exists\n",
      ">>>  Market capialization data of ABX could not be saved\n",
      "<<<  Market capialization data of ATVI already exists\n",
      "<<<  Market capialization data of ADSK already exists\n",
      "<<<  Market capialization data of ADM already exists\n",
      ">>>  Market capialization data of ORL.AX could not be saved\n",
      ">>>  Market capialization data of ICAD.PA could not be saved\n",
      "<<<  Market capialization data of HOTF already exists\n",
      ">>>  Market capialization data of BMH.AX could not be saved\n",
      "<<<  Market capialization data of WBA already exists\n",
      "<<<  Market capialization data of ARNA already exists\n",
      "<<<  Market capialization data of LUV already exists\n",
      "<<<  Market capialization data of ACAD already exists\n",
      "<<<  Market capialization data of PANW already exists\n",
      "<<<  Market capialization data of AMD already exists\n",
      ">>>  Market capialization data of HKFI could not be saved\n",
      "<<<  Market capialization data of NHMD already exists\n",
      ">>>  Market capialization data of ORJ.SG could not be saved\n"
     ]
    }
   ],
   "source": [
    "with Pool(processes=3) as pool:\n",
    "    pool.starmap(get_market_cap_data, zip(query_urls, itertools.repeat(json_path), itertools.repeat(csv_path)))\n",
    "print(\"<|>  Market capialization data of all stocks saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
